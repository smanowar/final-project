{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies and read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-41-c4bce657f015>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-41-c4bce657f015>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    db_string = f”postgresql://postgres:{db_password}@127.0.0.1:5432/stackoverflow”\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "#credentials for database\n",
    "\n",
    "#from sqlalchemy import create_engine\n",
    "#from config_db import db_password\n",
    "# Read ml_input table into dataframe\n",
    "db_string = f”postgresql://postgres:{db_password}@127.0.0.1:5432/stackoverflow”\n",
    "engine = create_engine(db_string)\n",
    "# table named ‘ml_input’ will be returned as a dataframe.\n",
    "ml_input_df = pd.read_sql_table(‘ml_input’, engine)\n",
    "ml_input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv for testing our ML models\n",
    "\n",
    "file_path='../Resources/ML_Input_Jan2021.csv'\n",
    "df=pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>q_score</th>\n",
       "      <th>q_score_tier</th>\n",
       "      <th>q_view_count</th>\n",
       "      <th>q_view_count_bin</th>\n",
       "      <th>q_title_char_count</th>\n",
       "      <th>q_title_char_count_bin</th>\n",
       "      <th>q_title_word_count</th>\n",
       "      <th>q_title_word_count_bin</th>\n",
       "      <th>q_body_word_count</th>\n",
       "      <th>q_body_len_bin</th>\n",
       "      <th>q_tags_count</th>\n",
       "      <th>q_day</th>\n",
       "      <th>q_hour</th>\n",
       "      <th>q_hour_min</th>\n",
       "      <th>accepted_answer_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65526420</td>\n",
       "      <td>65526457</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive Score (&gt;0)</td>\n",
       "      <td>62</td>\n",
       "      <td>50-16000</td>\n",
       "      <td>72</td>\n",
       "      <td>Medium (50-100)</td>\n",
       "      <td>13</td>\n",
       "      <td>Medium (10-20)</td>\n",
       "      <td>116</td>\n",
       "      <td>100-250</td>\n",
       "      <td>3</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "      <td>0.122066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65526423</td>\n",
       "      <td>65526533</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive Score (&gt;0)</td>\n",
       "      <td>48</td>\n",
       "      <td>40-50</td>\n",
       "      <td>48</td>\n",
       "      <td>Short (0 - 50)</td>\n",
       "      <td>8</td>\n",
       "      <td>Short (0 - 10)</td>\n",
       "      <td>58</td>\n",
       "      <td>50-100</td>\n",
       "      <td>2</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "      <td>0.475172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65526490</td>\n",
       "      <td>65526541</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive Score (&gt;0)</td>\n",
       "      <td>35</td>\n",
       "      <td>30-40</td>\n",
       "      <td>81</td>\n",
       "      <td>Medium (50-100)</td>\n",
       "      <td>13</td>\n",
       "      <td>Medium (10-20)</td>\n",
       "      <td>117</td>\n",
       "      <td>100-250</td>\n",
       "      <td>2</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>00:20</td>\n",
       "      <td>0.287423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65526419</td>\n",
       "      <td>65526554</td>\n",
       "      <td>3</td>\n",
       "      <td>Positive Score (&gt;0)</td>\n",
       "      <td>351</td>\n",
       "      <td>50-16000</td>\n",
       "      <td>76</td>\n",
       "      <td>Medium (50-100)</td>\n",
       "      <td>9</td>\n",
       "      <td>Short (0 - 10)</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;50</td>\n",
       "      <td>4</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "      <td>0.575997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65526523</td>\n",
       "      <td>65526577</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive Score (&gt;0)</td>\n",
       "      <td>117</td>\n",
       "      <td>50-16000</td>\n",
       "      <td>82</td>\n",
       "      <td>Medium (50-100)</td>\n",
       "      <td>14</td>\n",
       "      <td>Medium (10-20)</td>\n",
       "      <td>305</td>\n",
       "      <td>250-500</td>\n",
       "      <td>3</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>00:30</td>\n",
       "      <td>0.253412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       q_id  accepted_answer_id  q_score         q_score_tier  q_view_count  \\\n",
       "0  65526420            65526457        2  Positive Score (>0)            62   \n",
       "1  65526423            65526533        2  Positive Score (>0)            48   \n",
       "2  65526490            65526541        2  Positive Score (>0)            35   \n",
       "3  65526419            65526554        3  Positive Score (>0)           351   \n",
       "4  65526523            65526577        2  Positive Score (>0)           117   \n",
       "\n",
       "  q_view_count_bin  q_title_char_count q_title_char_count_bin  \\\n",
       "0         50-16000                  72        Medium (50-100)   \n",
       "1            40-50                  48         Short (0 - 50)   \n",
       "2            30-40                  81        Medium (50-100)   \n",
       "3         50-16000                  76        Medium (50-100)   \n",
       "4         50-16000                  82        Medium (50-100)   \n",
       "\n",
       "   q_title_word_count q_title_word_count_bin  q_body_word_count  \\\n",
       "0                  13         Medium (10-20)                116   \n",
       "1                   8         Short (0 - 10)                 58   \n",
       "2                  13         Medium (10-20)                117   \n",
       "3                   9         Short (0 - 10)                 50   \n",
       "4                  14         Medium (10-20)                305   \n",
       "\n",
       "  q_body_len_bin  q_tags_count   q_day  q_hour q_hour_min  \\\n",
       "0        100-250             3  Friday       0      00:05   \n",
       "1         50-100             2  Friday       0      00:06   \n",
       "2        100-250             2  Friday       0      00:20   \n",
       "3            <50             4  Friday       0      00:05   \n",
       "4        250-500             3  Friday       0      00:30   \n",
       "\n",
       "   accepted_answer_duration  \n",
       "0                  0.122066  \n",
       "1                  0.475172  \n",
       "2                  0.287423  \n",
       "3                  0.575997  \n",
       "4                  0.253412  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "- Dropped null values and dropped uncessary columns\n",
    "- Binned data in accepted_answer_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_title_word_count</th>\n",
       "      <th>q_title_word_count_bin</th>\n",
       "      <th>q_body_word_count</th>\n",
       "      <th>q_body_len_bin</th>\n",
       "      <th>q_tags_count</th>\n",
       "      <th>q_day</th>\n",
       "      <th>q_hour</th>\n",
       "      <th>accepted_answer_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>Medium (10-20)</td>\n",
       "      <td>116</td>\n",
       "      <td>100-250</td>\n",
       "      <td>3</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>Short (0 - 10)</td>\n",
       "      <td>58</td>\n",
       "      <td>50-100</td>\n",
       "      <td>2</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.475172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>Medium (10-20)</td>\n",
       "      <td>117</td>\n",
       "      <td>100-250</td>\n",
       "      <td>2</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.287423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Short (0 - 10)</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;50</td>\n",
       "      <td>4</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.575997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>Medium (10-20)</td>\n",
       "      <td>305</td>\n",
       "      <td>250-500</td>\n",
       "      <td>3</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   q_title_word_count q_title_word_count_bin  q_body_word_count  \\\n",
       "0                  13         Medium (10-20)                116   \n",
       "1                   8         Short (0 - 10)                 58   \n",
       "2                  13         Medium (10-20)                117   \n",
       "3                   9         Short (0 - 10)                 50   \n",
       "4                  14         Medium (10-20)                305   \n",
       "\n",
       "  q_body_len_bin  q_tags_count   q_day  q_hour  accepted_answer_duration  \n",
       "0        100-250             3  Friday       0                  0.122066  \n",
       "1         50-100             2  Friday       0                  0.475172  \n",
       "2        100-250             2  Friday       0                  0.287423  \n",
       "3            <50             4  Friday       0                  0.575997  \n",
       "4        250-500             3  Friday       0                  0.253412  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop identification columns also q_hour_min and q_body_len_bin columns as they are redundant to other columns\n",
    "\n",
    "filter_df=df[['q_title_word_count','q_title_word_count_bin','q_body_word_count','q_body_len_bin','q_tags_count','q_day','q_hour','accepted_answer_duration']]\n",
    "filter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df=filter_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin accepted_answer_duration\n",
    "\n",
    "answer_bins = [0, 24, 6000]\n",
    "answer_bins_group_names = [\"<1D\", \">1D\"]\n",
    "\n",
    "# Categorize score based on the bins.\n",
    "filter_df['accepted_answer_duration_bin'] = pd.cut(filter_df['accepted_answer_duration'], answer_bins, labels=answer_bins_group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_title_word_count</th>\n",
       "      <th>q_title_word_count_bin</th>\n",
       "      <th>q_body_word_count</th>\n",
       "      <th>q_body_len_bin</th>\n",
       "      <th>q_tags_count</th>\n",
       "      <th>q_day</th>\n",
       "      <th>q_hour</th>\n",
       "      <th>accepted_answer_duration</th>\n",
       "      <th>accepted_answer_duration_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>Medium (10-20)</td>\n",
       "      <td>116</td>\n",
       "      <td>100-250</td>\n",
       "      <td>3</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122066</td>\n",
       "      <td>&lt;1D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>Short (0 - 10)</td>\n",
       "      <td>58</td>\n",
       "      <td>50-100</td>\n",
       "      <td>2</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.475172</td>\n",
       "      <td>&lt;1D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>Medium (10-20)</td>\n",
       "      <td>117</td>\n",
       "      <td>100-250</td>\n",
       "      <td>2</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.287423</td>\n",
       "      <td>&lt;1D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Short (0 - 10)</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;50</td>\n",
       "      <td>4</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.575997</td>\n",
       "      <td>&lt;1D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>Medium (10-20)</td>\n",
       "      <td>305</td>\n",
       "      <td>250-500</td>\n",
       "      <td>3</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253412</td>\n",
       "      <td>&lt;1D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   q_title_word_count q_title_word_count_bin  q_body_word_count  \\\n",
       "0                  13         Medium (10-20)                116   \n",
       "1                   8         Short (0 - 10)                 58   \n",
       "2                  13         Medium (10-20)                117   \n",
       "3                   9         Short (0 - 10)                 50   \n",
       "4                  14         Medium (10-20)                305   \n",
       "\n",
       "  q_body_len_bin  q_tags_count   q_day  q_hour  accepted_answer_duration  \\\n",
       "0        100-250             3  Friday       0                  0.122066   \n",
       "1         50-100             2  Friday       0                  0.475172   \n",
       "2        100-250             2  Friday       0                  0.287423   \n",
       "3            <50             4  Friday       0                  0.575997   \n",
       "4        250-500             3  Friday       0                  0.253412   \n",
       "\n",
       "  accepted_answer_duration_bin  \n",
       "0                          <1D  \n",
       "1                          <1D  \n",
       "2                          <1D  \n",
       "3                          <1D  \n",
       "4                          <1D  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q_title_word_count                 int64\n",
       "q_title_word_count_bin            object\n",
       "q_body_word_count                  int64\n",
       "q_body_len_bin                    object\n",
       "q_tags_count                       int64\n",
       "q_day                             object\n",
       "q_hour                             int64\n",
       "accepted_answer_duration         float64\n",
       "accepted_answer_duration_bin    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create features and encode our features using pd.get_dummies\n",
    "\n",
    "## Run Models Using Binned Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_tags_count</th>\n",
       "      <th>q_hour</th>\n",
       "      <th>q_title_word_count_bin_Long (20-30)</th>\n",
       "      <th>q_title_word_count_bin_Medium (10-20)</th>\n",
       "      <th>q_title_word_count_bin_Short (0 - 10)</th>\n",
       "      <th>q_title_word_count_bin_XL (30+)</th>\n",
       "      <th>q_body_len_bin_100-250</th>\n",
       "      <th>q_body_len_bin_250-500</th>\n",
       "      <th>q_body_len_bin_50-100</th>\n",
       "      <th>q_body_len_bin_500-10000</th>\n",
       "      <th>q_body_len_bin_&lt;50</th>\n",
       "      <th>q_day_Friday</th>\n",
       "      <th>q_day_Monday</th>\n",
       "      <th>q_day_Saturday</th>\n",
       "      <th>q_day_Sunday</th>\n",
       "      <th>q_day_Thursday</th>\n",
       "      <th>q_day_Tuesday</th>\n",
       "      <th>q_day_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   q_tags_count  q_hour  q_title_word_count_bin_Long (20-30)  \\\n",
       "0             3       0                                    0   \n",
       "1             2       0                                    0   \n",
       "2             2       0                                    0   \n",
       "3             4       0                                    0   \n",
       "4             3       0                                    0   \n",
       "\n",
       "   q_title_word_count_bin_Medium (10-20)  \\\n",
       "0                                      1   \n",
       "1                                      0   \n",
       "2                                      1   \n",
       "3                                      0   \n",
       "4                                      1   \n",
       "\n",
       "   q_title_word_count_bin_Short (0 - 10)  q_title_word_count_bin_XL (30+)  \\\n",
       "0                                      0                                0   \n",
       "1                                      1                                0   \n",
       "2                                      0                                0   \n",
       "3                                      1                                0   \n",
       "4                                      0                                0   \n",
       "\n",
       "   q_body_len_bin_100-250  q_body_len_bin_250-500  q_body_len_bin_50-100  \\\n",
       "0                       1                       0                      0   \n",
       "1                       0                       0                      1   \n",
       "2                       1                       0                      0   \n",
       "3                       0                       0                      0   \n",
       "4                       0                       1                      0   \n",
       "\n",
       "   q_body_len_bin_500-10000  q_body_len_bin_<50  q_day_Friday  q_day_Monday  \\\n",
       "0                         0                   0             1             0   \n",
       "1                         0                   0             1             0   \n",
       "2                         0                   0             1             0   \n",
       "3                         0                   1             1             0   \n",
       "4                         0                   0             1             0   \n",
       "\n",
       "   q_day_Saturday  q_day_Sunday  q_day_Thursday  q_day_Tuesday  \\\n",
       "0               0             0               0              0   \n",
       "1               0             0               0              0   \n",
       "2               0             0               0              0   \n",
       "3               0             0               0              0   \n",
       "4               0             0               0              0   \n",
       "\n",
       "   q_day_Wednesday  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our features\n",
    "X_binned = filter_df.drop(['q_title_word_count','q_body_word_count','accepted_answer_duration','accepted_answer_duration_bin'], axis=1)\n",
    "X_binned = pd.get_dummies(X_binned)\n",
    "\n",
    "# Create our target\n",
    "\n",
    "y = filter_df[\"accepted_answer_duration_bin\"]\n",
    "\n",
    "X_binned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1D    386497\n",
       ">1D     61007\n",
       "Name: accepted_answer_duration_bin, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data to training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_binned_train, X_binned_test, y_train, y_test = train_test_split(X_binned,y,random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use this one for predictions/pickle\n",
    "# Random Forest Classifier \n",
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "brfc_bin = BalancedRandomForestClassifier(n_estimators=100,random_state=1)\n",
    "rf_bin = brfc_bin.fit(X_binned_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5529495476166002"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred=rf_bin.predict(X_binned_test)\n",
    "ba_balanced_forest_binned=balanced_accuracy_score(y_test,y_pred)\n",
    "ba_balanced_forest_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Less Than 24 Hours</th>\n",
       "      <th>Predicted Greater Than 24 Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Less Than 24 Hours</th>\n",
       "      <td>52583</td>\n",
       "      <td>44041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Greater Than 24 Hours</th>\n",
       "      <td>6685</td>\n",
       "      <td>8567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Predicted Less Than 24 Hours  \\\n",
       "Actual Less Than 24 Hours                            52583   \n",
       "Actual Greater Than 24 Hours                          6685   \n",
       "\n",
       "                              Predicted Greater Than 24 Hours  \n",
       "Actual Less Than 24 Hours                               44041  \n",
       "Actual Greater Than 24 Hours                             8567  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "\n",
    "cm_rf_binned_df=pd.DataFrame(cm,\n",
    "                  index=[\"Actual Less Than 24 Hours\", \"Actual Greater Than 24 Hours\"],\n",
    "                  columns=[\"Predicted Less Than 24 Hours\", \"Predicted Greater Than 24 Hours\"])\n",
    "cm_rf_binned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print additional scores for analysis: precision, recall, and f1\n",
    "## See summary in comparison section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imbalanced classification report\n",
    "icr_balanced_forest_binned=classification_report_imbalanced(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6448099311012391, 'q_hour'),\n",
       " (0.15952956319103145, 'q_tags_count'),\n",
       " (0.030754420450241828, 'q_body_len_bin_500-10000'),\n",
       " (0.02255523109476319, 'q_body_len_bin_250-500'),\n",
       " (0.017754638309173856, 'q_day_Friday'),\n",
       " (0.016938711743055102, 'q_body_len_bin_50-100'),\n",
       " (0.012897456760070442, 'q_title_word_count_bin_Short (0 - 10)'),\n",
       " (0.012591943934120229, 'q_title_word_count_bin_Medium (10-20)'),\n",
       " (0.009981839334289895, 'q_day_Wednesday'),\n",
       " (0.009796000398893046, 'q_body_len_bin_100-250'),\n",
       " (0.00965609382440849, 'q_day_Thursday'),\n",
       " (0.00952906359147217, 'q_day_Monday'),\n",
       " (0.009190572168048906, 'q_day_Saturday'),\n",
       " (0.00918473984574853, 'q_day_Tuesday'),\n",
       " (0.008944454467710064, 'q_title_word_count_bin_Long (20-30)'),\n",
       " (0.008418534047194514, 'q_day_Sunday'),\n",
       " (0.007151594451761099, 'q_body_len_bin_<50'),\n",
       " (0.0003152112867781374, 'q_title_word_count_bin_XL (30+)')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "sorted(zip(rf_bin.feature_importances_, X_binned.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easy Ensemble Classifier\n",
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the EasyEnsembleClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "ensemble_binned=EasyEnsembleClassifier(n_estimators=100,random_state=1)\n",
    "\n",
    "eec_binned = ensemble_binned.fit(X_binned_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5718322967326592"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred=eec_binned.predict(X_binned_test)\n",
    "ba_easy_ensemble_binned=balanced_accuracy_score(y_test,y_pred)\n",
    "ba_easy_ensemble_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Less Than 24 Hours</th>\n",
       "      <th>Predicted Greater Than 24 Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Less Than 24 Hours</th>\n",
       "      <td>58348</td>\n",
       "      <td>38276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Greater Than 24 Hours</th>\n",
       "      <td>7019</td>\n",
       "      <td>8233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Predicted Less Than 24 Hours  \\\n",
       "Actual Less Than 24 Hours                            58348   \n",
       "Actual Greater Than 24 Hours                          7019   \n",
       "\n",
       "                              Predicted Greater Than 24 Hours  \n",
       "Actual Less Than 24 Hours                               38276  \n",
       "Actual Greater Than 24 Hours                             8233  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "cm=confusion_matrix(y_test, y_pred)\n",
    " \n",
    "cm_ee_binned_df=pd.DataFrame(cm,\n",
    "                  index=[\"Actual Less Than 24 Hours\", \"Actual Greater Than 24 Hours\"],\n",
    "                  columns=[\"Predicted Less Than 24 Hours\", \"Predicted Greater Than 24 Hours\"])\n",
    "\n",
    "cm_ee_binned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print additional scores for analysis: precision, recall, and f1\n",
    "## See comparison section below for summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imbalanced classification report\n",
    "icr_easy_ensemble_binned=classification_report_imbalanced(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier_binned = LogisticRegression()\n",
    "classifier_binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_binned.fit(X_binned_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8636734718199912\n",
      "Testing Data Score: 0.8636704923307948\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier_binned.score(X_binned_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier_binned.score(X_binned_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:\t\t['<1D', '>1D', '>1D', '<1D', '<1D', '<1D', '>1D', '<1D', '<1D', '<1D']\n",
      "Predicted:\t['<1D', '<1D', '<1D', '<1D', '<1D', '<1D', '<1D', '<1D', '<1D', '<1D']\n"
     ]
    }
   ],
   "source": [
    "print(f'Actual:\\t\\t{list(y_test[:10])}')\n",
    "print(\"Predicted:\\t{}\".format(list(classifier_binned.predict(X_binned_test[:10]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred=classifier_binned.predict(X_binned_test)\n",
    "ba_logistic_regression_binned=balanced_accuracy_score(y_test,y_pred)\n",
    "ba_logistic_regression_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Less Than 24 Hours</th>\n",
       "      <th>Predicted Greater Than 24 Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Less Than 24 Hours</th>\n",
       "      <td>96624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Greater Than 24 Hours</th>\n",
       "      <td>15252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Predicted Less Than 24 Hours  \\\n",
       "Actual Less Than 24 Hours                            96624   \n",
       "Actual Greater Than 24 Hours                         15252   \n",
       "\n",
       "                              Predicted Greater Than 24 Hours  \n",
       "Actual Less Than 24 Hours                                   0  \n",
       "Actual Greater Than 24 Hours                                0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "cm=confusion_matrix(y_test, y_pred)\n",
    " \n",
    "cm_logreg_binned_df=pd.DataFrame(cm,\n",
    "                  index=[\"Actual Less Than 24 Hours\", \"Actual Greater Than 24 Hours\"],\n",
    "                  columns=[\"Predicted Less Than 24 Hours\", \"Predicted Greater Than 24 Hours\"])\n",
    "\n",
    "cm_logreg_binned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print additional scores for analysis: precision, recall, and f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imbalanced classification report\n",
    "icr_logistic_regression_binned=classification_report_imbalanced(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Between the Models using Binned Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Balanced Random Forest Classifier algortihm, using binned features the balanced accuracy score is 0.5529495476166002\n",
      "\n",
      "and the imbalanced classifcation report is:\n",
      "\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        <1D       0.86      1.00      0.00      0.93      0.00      0.00     96624\n",
      "        >1D       0.00      0.00      1.00      0.00      0.00      0.00     15252\n",
      "\n",
      "avg / total       0.75      0.86      0.14      0.80      0.00      0.00    111876\n",
      "\n",
      "For the Easy Ensemble AdaBoost Classifier algortihm, using binned features the balanced accuracy score is 0.5718322967326592\n",
      "\n",
      "and the imbalanced classifcation report is:\n",
      "\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        <1D       0.89      0.60      0.54      0.72      0.57      0.33     96624\n",
      "        >1D       0.18      0.54      0.60      0.27      0.57      0.32     15252\n",
      "\n",
      "avg / total       0.80      0.60      0.55      0.66      0.57      0.33    111876\n",
      "\n",
      "For the Logistic Regression algortihm, using binned features the balanced accuracy score is 0.5\n",
      "\n",
      "and the imbalanced classifcation report is:\n",
      "\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        <1D       0.86      1.00      0.00      0.93      0.00      0.00     96624\n",
      "        >1D       0.00      0.00      1.00      0.00      0.00      0.00     15252\n",
      "\n",
      "avg / total       0.75      0.86      0.14      0.80      0.00      0.00    111876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Summary of findings\n",
    "\n",
    "print(f'For the Balanced Random Forest Classifier algortihm, using binned features the balanced accuracy score is {ba_balanced_forest_binned}' \n",
    "      f'\\n\\nand the imbalanced classifcation report is:\\n\\n{icr_balanced_forest_binned}')\n",
    "\n",
    "print(f'For the Easy Ensemble AdaBoost Classifier algortihm, using binned features the balanced accuracy score is {ba_easy_ensemble_binned}' \n",
    "      f'\\n\\nand the imbalanced classifcation report is:\\n\\n{icr_easy_ensemble_binned}')\n",
    "\n",
    "print(f'For the Logistic Regression algortihm, using binned features the balanced accuracy score is {ba_logistic_regression_binned}' \n",
    "      f'\\n\\nand the imbalanced classifcation report is:\\n\\n{icr_logistic_regression_binned}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Models Using Non-Binned Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_title_word_count</th>\n",
       "      <th>q_body_word_count</th>\n",
       "      <th>q_tags_count</th>\n",
       "      <th>q_hour</th>\n",
       "      <th>q_day_Friday</th>\n",
       "      <th>q_day_Monday</th>\n",
       "      <th>q_day_Saturday</th>\n",
       "      <th>q_day_Sunday</th>\n",
       "      <th>q_day_Thursday</th>\n",
       "      <th>q_day_Tuesday</th>\n",
       "      <th>q_day_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>305</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   q_title_word_count  q_body_word_count  q_tags_count  q_hour  q_day_Friday  \\\n",
       "0                  13                116             3       0             1   \n",
       "1                   8                 58             2       0             1   \n",
       "2                  13                117             2       0             1   \n",
       "3                   9                 50             4       0             1   \n",
       "4                  14                305             3       0             1   \n",
       "\n",
       "   q_day_Monday  q_day_Saturday  q_day_Sunday  q_day_Thursday  q_day_Tuesday  \\\n",
       "0             0               0             0               0              0   \n",
       "1             0               0             0               0              0   \n",
       "2             0               0             0               0              0   \n",
       "3             0               0             0               0              0   \n",
       "4             0               0             0               0              0   \n",
       "\n",
       "   q_day_Wednesday  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our features\n",
    "X = filter_df.drop(['accepted_answer_duration','accepted_answer_duration_bin','q_body_len_bin','q_title_word_count_bin'], axis=1)\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Create our target\n",
    "\n",
    "y = filter_df[\"accepted_answer_duration_bin\"]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "brfc = BalancedRandomForestClassifier(n_estimators=100,random_state=1)\n",
    "rf = brfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5416843322951042"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred=rf.predict(X_test)\n",
    "ba_balanced_forest=balanced_accuracy_score(y_test,y_pred)\n",
    "ba_balanced_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Less Than 24 Hours</th>\n",
       "      <th>Predicted Greater Than 24 Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Less Than 24 Hours</th>\n",
       "      <td>53789</td>\n",
       "      <td>42835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Greater Than 24 Hours</th>\n",
       "      <td>7219</td>\n",
       "      <td>8033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Predicted Less Than 24 Hours  \\\n",
       "Actual Less Than 24 Hours                            53789   \n",
       "Actual Greater Than 24 Hours                          7219   \n",
       "\n",
       "                              Predicted Greater Than 24 Hours  \n",
       "Actual Less Than 24 Hours                               42835  \n",
       "Actual Greater Than 24 Hours                             8033  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "\n",
    "cm_rf_df=pd.DataFrame(cm,\n",
    "                  index=[\"Actual Less Than 24 Hours\", \"Actual Greater Than 24 Hours\"],\n",
    "                  columns=[\"Predicted Less Than 24 Hours\", \"Predicted Greater Than 24 Hours\"])\n",
    "cm_rf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print additional scores for analysis: precision, recall, and f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imbalanced classification report\n",
    "icr_balanced_forest=classification_report_imbalanced(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5179621297158278, 'q_body_word_count'),\n",
       " (0.21197150745482093, 'q_title_word_count'),\n",
       " (0.21058713070897694, 'q_hour'),\n",
       " (0.03322278365703065, 'q_tags_count'),\n",
       " (0.0041018542699754875, 'q_day_Thursday'),\n",
       " (0.004037448550990621, 'q_day_Monday'),\n",
       " (0.003941187315642853, 'q_day_Wednesday'),\n",
       " (0.003926222518898671, 'q_day_Friday'),\n",
       " (0.003717719825143495, 'q_day_Tuesday'),\n",
       " (0.0032999633360740175, 'q_day_Saturday'),\n",
       " (0.0032320526466187134, 'q_day_Sunday')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "sorted(zip(rf.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easy Ensemble Classifier\n",
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the EasyEnsembleClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "ensemble=EasyEnsembleClassifier(n_estimators=100,random_state=1)\n",
    "\n",
    "eec = ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred=eec.predict(X_test)\n",
    "ba_easy_ensemble=balanced_accuracy_score(y_test,y_pred)\n",
    "ba_easy_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "cm=confusion_matrix(y_test, y_pred)\n",
    " \n",
    "cm_df=pd.DataFrame(cm,\n",
    "                  index=[\"Actual <1D\", \"Actual >1D\"],\n",
    "                  columns=[\"Predicted <1D\", \"Predicted >1D\"])\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print additional scores for analysis: precision, recall, and f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imbalanced classification report\n",
    "icr_easy_ensemble=classification_report_imbalanced(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Actual:\\t\\t{list(y_test[:10])}')\n",
    "print(\"Predicted:\\t{}\".format(list(classifier.predict(X_test[:10]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 21 features per sample; expecting 25",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-d049c191ced4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Calculated the balanced accuracy score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mba_logistic_regression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbalanced_accuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mba_logistic_regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \"\"\"\n\u001b[1;32m--> 309\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[1;32m--> 289\u001b[1;33m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 21 features per sample; expecting 25"
     ]
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred=classifier.predict(X_test)\n",
    "ba_logistic_regression=balanced_accuracy_score(y_test,y_pred)\n",
    "ba_logistic_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted &lt;1D</th>\n",
       "      <th>Predicted &gt;1D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual &lt;1D</th>\n",
       "      <td>58915</td>\n",
       "      <td>37695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual &gt;1D</th>\n",
       "      <td>5982</td>\n",
       "      <td>9263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted <1D  Predicted >1D\n",
       "Actual <1D          58915          37695\n",
       "Actual >1D           5982           9263"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "cm=confusion_matrix(y_test, y_pred)\n",
    " \n",
    "cm_df=pd.DataFrame(cm,\n",
    "                  index=[\"Actual <1D\", \"Actual >1D\"],\n",
    "                  columns=[\"Predicted <1D\", \"Predicted >1D\"])\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imbalanced classification report\n",
    "icr_logistic_regression=classification_report_imbalanced(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'icr_balanced_forest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-72159948b5dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Summary of findings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m print(f'For the Balanced Random Forest Classifier algortihm, the balanced accuracy score is {ba_balanced_forest}' \n\u001b[0m\u001b[0;32m      4\u001b[0m       f'\\n\\nand the imbalanced classifcation report is:\\n\\n{icr_balanced_forest}')\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'icr_balanced_forest' is not defined"
     ]
    }
   ],
   "source": [
    "#Summary of findings\n",
    "\n",
    "print(f'For the Balanced Random Forest Classifier algortihm, the balanced accuracy score is {ba_balanced_forest}' \n",
    "      f'\\n\\nand the imbalanced classifcation report is:\\n\\n{icr_balanced_forest}')\n",
    "\n",
    "print(f'For the Easy Ensemble AdaBoost Classifier algortihm, using binned features the balanced accuracy score is {ba_easy_ensemble_binned}' \n",
    "      f'\\n\\nand the imbalanced classifcation report is:\\n\\n{icr_easy_ensemble_binned}')\n",
    "\n",
    "print(f'For the Logistic Regression algortihm, the balanced accuracy score is {ba_logistic_regression}' \n",
    "      f'\\n\\nand the imbalanced classifcation report is:\\n\\n{icr_logistic_regression}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
